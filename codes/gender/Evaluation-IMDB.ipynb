{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Bias Uncovering Test Case (BTC) for Gender Bias"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from metric import evaluate_btc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Measuring the Performance of the Fine-tuned SA models on the Test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def load_pickle(fpath):\n",
    "    with open(fpath, 'rb') as f:\n",
    "        pred = pickle.load(f)\n",
    "    return pred\n",
    "\n",
    "def accuracy(label, prediction):\n",
    "    return 100 * sum(label == prediction) / len(label)\n",
    "\n",
    "def calculate_test_accuracy(task, model) :\n",
    "    label_path = f\"../../asset/{task}/test.csv\"\n",
    "    pred_path = f\"../../asset/{task}/predictions/{model}.pkl\"\n",
    "\n",
    "\n",
    "    test_df = pd.read_csv(label_path, header=None, sep=\"\\t\")\n",
    "\n",
    "    test_labels = test_df[0].values\n",
    "    predicitons = load_pickle(pred_path)\n",
    "\n",
    "    return accuracy(test_labels, predicitons)\n",
    "\n",
    "\n",
    "task = \"imdb\"\n",
    "model = \"bert-base-uncased\"\n",
    "\n",
    "\n",
    "calculate_test_accuracy(task, model)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "92.568"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Measuring the BTC that can be found by BiasFinder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "mutation_tool = \"biasfinder\"\n",
    "bias_type = \"gender\"\n",
    "task = \"imdb\" # dataset used for fine-tuning\n",
    "model = \"bert-base-uncased\"\n",
    "# model = \"bert-base-cased\"\n",
    "# model = \"microsoft/mpnet-base\"\n",
    "mutant = \"imdb\" # dataset used for generating mutants\n",
    "\n",
    "def load_mutant_and_prediction(mutation_tool, bias_type, mutant):\n",
    "    base_dir = f\"../../data/{mutation_tool}/{bias_type}/{mutant}/\"\n",
    "    if mutation_tool == \"biasfinder\" :\n",
    "        df = pd.read_csv(base_dir + \"test.csv\", header=None, sep=\"\\t\", names=[\"label\", \"mutant\", \"template\", \"original\", \"gender\"])\n",
    "    elif mutation_tool == \"eec\":\n",
    "        df = pd.read_csv(base_dir + \"test.csv\", header=None, sep=\"\\t\", names=[\"label\", \"mutant\", \"template\", \"original\", \"person\", \"gender\", \"emotion\"])\n",
    "\n",
    "    df[\"template\"] = df[\"template\"].astype(\"category\")\n",
    "    df[\"template_id\"] = df[\"template\"].cat.codes\n",
    "\n",
    "    prediction_fpath = os.path.join(base_dir, f\"predictions/{model}.pkl\")\n",
    "    pred = load_pickle(prediction_fpath)\n",
    "\n",
    "    df[\"prediction\"] = pred\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = load_mutant_and_prediction(mutation_tool, bias_type, mutant)\n",
    "\n",
    "df.head()\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   label                                             mutant  \\\n",
       "0      0  I hated the book. A guy meets a smart dog, get...   \n",
       "1      0  I hated the book. A guy meets a smart dog, get...   \n",
       "2      1  The Great Dictator is a beyondexcellent film. ...   \n",
       "3      1  The Great Dictator is a beyondexcellent film. ...   \n",
       "4      1  The Great Dictator is a beyondexcellent film. ...   \n",
       "\n",
       "                                            template  \\\n",
       "0  I hated the book. A guy meets a smart dog, get...   \n",
       "1  I hated the book. A guy meets a smart dog, get...   \n",
       "2  The Great Dictator is a beyondexcellent film. ...   \n",
       "3  The Great Dictator is a beyondexcellent film. ...   \n",
       "4  The Great Dictator is a beyondexcellent film. ...   \n",
       "\n",
       "                                            original  gender  template_id  \\\n",
       "0  I hated the book. A guy meets a smart dog, get...    male          929   \n",
       "1  I hated the book. A guy meets a smart dog, get...  female          929   \n",
       "2  The Great Dictator is a beyondexcellent film. ...    male         1980   \n",
       "3  The Great Dictator is a beyondexcellent film. ...    male         1980   \n",
       "4  The Great Dictator is a beyondexcellent film. ...    male         1980   \n",
       "\n",
       "   prediction  \n",
       "0           0  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mutant</th>\n",
       "      <th>template</th>\n",
       "      <th>original</th>\n",
       "      <th>gender</th>\n",
       "      <th>template_id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I hated the book. A guy meets a smart dog, get...</td>\n",
       "      <td>I hated the book. A guy meets a smart dog, get...</td>\n",
       "      <td>I hated the book. A guy meets a smart dog, get...</td>\n",
       "      <td>male</td>\n",
       "      <td>929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I hated the book. A guy meets a smart dog, get...</td>\n",
       "      <td>I hated the book. A guy meets a smart dog, get...</td>\n",
       "      <td>I hated the book. A guy meets a smart dog, get...</td>\n",
       "      <td>female</td>\n",
       "      <td>929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>The Great Dictator is a beyondexcellent film. ...</td>\n",
       "      <td>The Great Dictator is a beyondexcellent film. ...</td>\n",
       "      <td>The Great Dictator is a beyondexcellent film. ...</td>\n",
       "      <td>male</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The Great Dictator is a beyondexcellent film. ...</td>\n",
       "      <td>The Great Dictator is a beyondexcellent film. ...</td>\n",
       "      <td>The Great Dictator is a beyondexcellent film. ...</td>\n",
       "      <td>male</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The Great Dictator is a beyondexcellent film. ...</td>\n",
       "      <td>The Great Dictator is a beyondexcellent film. ...</td>\n",
       "      <td>The Great Dictator is a beyondexcellent film. ...</td>\n",
       "      <td>male</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(\"Accuracy on mutants: {:.2f}%\".format(accuracy(df[\"label\"],df[\"prediction\"])))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 93.29%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def print_evaluation(evaluation):\n",
    "    print(\"# Mutants \\t:\", evaluation[\"mutant\"])\n",
    "    print(\"# Templates \\t:\", evaluation[\"template\"])\n",
    "    print(\"# BTCs \\t\\t:\", evaluation[\"btc\"])\n",
    "\n",
    "evaluation = evaluate_btc(df[\"label\"], df[\"prediction\"], df[\"mutant\"], df[\"template\"], \"gender\", df[\"gender\"])\n",
    "print_evaluation(evaluation)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# Mutants \t: 153866\n",
      "# Templates \t: 3015\n",
      "# BTCs \t\t: 5543\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# models = [\"bert-base-uncased\", \"bert-base-cased\", \"roberta-base\", \"albert-base-v2\", \"microsoft/mpnet-base\", \"microsoft/deberta-base\", \"facebook/muppert-roberta-base\", \"google/electra-base-generator\"]\n",
    "\n",
    "# fine-tune\n",
    "# \n",
    "\n",
    "# test accuracy\n",
    "# \"microsoft/deberta-base\"\n",
    "\n",
    "# predict mutants\n",
    "# \"bert-base-cased\", \"roberta-base\", \"albert-base-v2\",\n",
    "\n",
    "\n",
    "models = [\"bert-base-uncased\", \"microsoft/mpnet-base\"]\n",
    "\n",
    "mutation_tool = \"biasfinder\"\n",
    "bias_type = \"gender\"\n",
    "task = \"imdb\"  # dataset used for fine-tuning\n",
    "mutant = \"imdb\"  # dataset used for generating mutants\n",
    "\n",
    "d = pd.DataFrame(columns=[\"tool\", \"model\", \"accuracy\",\n",
    "                          \"template\", \"mutant\", \"btc\"])\n",
    "\n",
    "for model in models :\n",
    "    test_accuracy = calculate_test_accuracy(task, model)\n",
    "    df = load_mutant_and_prediction(mutation_tool, bias_type, mutant)\n",
    "    evaluation = evaluate_btc(df[\"label\"], df[\"prediction\"],\n",
    "                            df[\"mutant\"], df[\"template\"], \"gender\", df[\"gender\"])\n",
    "\n",
    "    d = d.append(\n",
    "            {\n",
    "                \"model\": model, \n",
    "                \"accuracy\": test_accuracy, \n",
    "                \"tool\": mutation_tool, \n",
    "                \"template\": evaluation['template'], \n",
    "                \"mutant\": evaluation['mutant'],\n",
    "                \"btc\" : evaluation['btc']\n",
    "            }, \n",
    "            ignore_index=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "d"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  model  accuracy        tool template  mutant   btc\n",
       "0     bert-base-uncased    92.568  biasfinder     3015  153866  5543\n",
       "1  microsoft/mpnet-base    93.616  biasfinder     3015  153866  4849"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tool</th>\n",
       "      <th>template</th>\n",
       "      <th>mutant</th>\n",
       "      <th>btc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>92.568</td>\n",
       "      <td>biasfinder</td>\n",
       "      <td>3015</td>\n",
       "      <td>153866</td>\n",
       "      <td>5543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>microsoft/mpnet-base</td>\n",
       "      <td>93.616</td>\n",
       "      <td>biasfinder</td>\n",
       "      <td>3015</td>\n",
       "      <td>153866</td>\n",
       "      <td>4849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}